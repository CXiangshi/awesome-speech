# awesome-speech
this is a treasure-house of speech

## 目录
* [语音识别（ASR,STT）](#1)
  * [page](#1.1)
  * [open source library/toolbox](#1.2)
  * [corpus/dataset](#1.3)
  * [教程（Tutorial）](#1.4)
* [语音合成（Speech Synthesis,TTS）](#2)
  * [page](#2.1)
  * [open source library/toolbox](#2.2)
  * [corpus/dataset](#2.3)
  * [教程（Tutorial）](#2.4)
* [声纹识别（Speaker Recognition）](#3)
  * [page](#3.1)
  * [open source library/toolbox](#3.2)
  * [corpus/dataset](#3.3)
  * [教程（Tutorial）](#3.4)
* [对话系统（Dialogue Systems）](#4)
  * [page](#4.1)
  * [open source library/toolbox](#4.2)
  * [corpus/dataset](#4.3)
  * [教程（Tutorial）](#4.4)
* [前端（front end）](#5)
  * [Speech Processing](#5.1)
  * [Audio I/O](#5.2)
  * [Source Separation](#5.3)
  * [Feature Extraction](#5.4)
* [resource](#6)
* [pages](#7)

## <h2 id="1">语音识别</h2>
 ### <h3 id="1.2">open source library/toolbox</h3>
 #### HTK
* http://htk.eng.cam.ac.uk/download.shtml)
 #### Kaldi:
* https://github.com/kaldi-asr/kaldi
 #### py-kaldi-asr
* https://github.com/gooofy/py-kaldi-asr
 #### Dan's DNN implementation:
* http://kaldi-asr.org/doc/dnn2.html
 #### pytorch-kaldi
* https://github.com/mravanelli/pytorch-kaldi/
 #### kaldi-lstm
* https://github.com/dophist/kaldi-lstm
 #### keras-kaldi
* https://github.com/dspavankumar/keras-kaldi
 #### Kaldi+PDNN
* https://github.com/yajiemiao/kaldipdnn
 #### kaldi-ivector
* https://github.com/idiap/kaldi-ivector
 #### CSLT-Sparse-DNN-Toolkit
* https://github.com/wyq730/CSLT-Sparse-DNN-Toolkit
 #### featxtra
* https://github.com/mvansegbroeck/featxtra
 #### kaldi 在线中文识别系统搭建
* https://blog.csdn.net/shichaog/article/details/73655628
 #### Sphinx
* https://cmusphinx.github.io/
* https://github.com/cmusphinx
* https://github.com/cmusphinx/pocketsphinx
 #### OpenFst
* http://www.openfst.org/twiki/bin/view/FST/WebHome
 #### MIT Spoken Language Systems
* https://groups.csail.mit.edu/sls/downloads/
 #### Julius
* http://julius.osdn.jp/en_index.php
* https://github.com/julius-speech/julius
 #### Bavieca
* http://www.bavieca.org/
 #### Simon 
* https://simon.kde.org/
 #### SRILM
* https://www.sri.com/engage/products-solutions/sri-language-modeling-toolkit
* https://github.com/njsmith/pysrilm
 #### ISIP
* https://www.isip.piconepress.com/projects/speech/
 #### MIT Finite-State Transducer (FST) Toolkit
* http://groups.csail.mit.edu/sls/downloads/
 #### MIT Language Modeling (MITLM) Toolkit
* http://groups.csail.mit.edu/sls/downloads/
 #### OpenGrm
* http://www.openfst.org/twiki/bin/view/GRM/WebHome
 #### SpeechRecognition
* https://github.com/Uberi/speech_recognition
 #### SpeechPy
* https://github.com/astorfi/speechpy
 #### Aalto
* https://github.com/aalto-speech/AaltoASR
 #### google-cloud-speech
* https://pypi.org/project/google-cloud-speech/
 #### apiai
https://pypi.org/project/apiai/
 #### wit
* https://github.com/wit-ai/pywit
 #### dejavu
* https://github.com/worldveil/dejavu
 #### uSpeech
* https://github.com/arjo129/uSpeech
 #### Juicer
* https://github.com/idiap/juicer
 #### dragonfly
* https://github.com/t4ngo/dragonfly
 #### SPTK
* http://sp-tk.sourceforge.net/
 #### Speech Recognition Grammar Specification
* https://www.w3.org/TR/speech-grammar/
 #### Automatic_Speech_Recognition
* https://github.com/zzw922cn/Automatic_Speech_Recognition
 #### speech-to-text-wavenet
* https://github.com/buriburisuri/speech-to-text-wavenet
 #### tensorflow-speech-recognition
* https://github.com/pannous/tensorflow-speech-recognition
 #### tensorflow_speech_recognition_demo
* https://github.com/llSourcell/tensorflow_speech_recognition_demo
 #### AVSR-Deep-Speech
* https://github.com/pandeydivesh15/AVSR-Deep-Speech


## <h2 id="2">语音合成</h2>
### <h3 id="2.2">open source library/toolbox</h3>
 #### WORLD
* https://github.com/mmorise/World
 #### HTS
* http://hts.sp.nitech.ac.jp/
* http://hts-engine.sourceforge.net/
 #### Tacotron2
* https://github.com/riverphoenix/tacotron2
* https://github.com/A-Jacobson/tacotron2
* https://github.com/selap91/Tacotron2
* https://github.com/LGizkde/Tacotron2_Tao_Shujie
* https://github.com/rlawns1016/Tacotron2
* https://github.com/CapstoneInha/Tacotron2-rehearsal
 #### Merlin
* https://github.com/CSTR-Edinburgh/merlin
 #### mozilla TTS
* https://github.com/mozilla/TTS
 #### Flite
* http://www.speech.cs.cmu.edu/flite/
* https://github.com/festvox/flite
 #### Speect
* http://speect.sourceforge.net/
 #### Festival
* https://github.com/festvox/festival
 #### eSpeak
* http://espeak.sourceforge.net/
 #### nnmnkwii
* https://github.com/r9y9/nnmnkwii
 #### Ossian
* https://github.com/CSTR-Edinburgh/Ossian
 #### Neural_Network_Voices
* https://github.com/llSourcell/Neural_Network_Voices
 #### pggan-pytorch
* https://github.com/deepsound-project/pggan-pytorch
 #### cainteoir-engine
* https://github.com/rhdunn/cainteoir-engine
 #### marytts(JAVA)
* https://github.com/marytts/marytts

## <h2 id="3">声纹识别</h2>
 ### <h3 id="3.2">open source library/toolbox</h3>
 #### speaker-recognition-py3
* https://github.com/crouchred/speaker-recognition-py3

## <h2 id="4">对话系统</h3>
 ### <h2 id="4.2">open source library/toolbox</h3>
  #### PyDial
* http://www.camdial.org/pydial/
  #### alex
* https://github.com/UFAL-DSG/alex

## <h2 id="5">前端</h2>
 ### <h3 id="5.1">Speech Processing</h3>
 #### madmom
* https://github.com/CPJKU/madmom
 #### pydub
* https://github.com/jiaaro/pydub
 #### kapre: Keras Audio Preprocessors
* https://github.com/keunwoochoi/kapre
 #### BTK
* http://distantspeechrecognition.sourceforge.net/
 #### Signal-Processing
* https://github.com/mathEnthusaistCodes/Signal-Processing
 #### pyroomacoustics
* https://github.com/LCAV/pyroomacoustics
 #### librosa
* https://github.com/librosa/librosa
 #### VOICEBOX
* http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html
 #### Pitch Detection
* http://note.sonots.com/SciSoftware/Pitch.html
 #### TFTB
* http://tftb.nongnu.org/
 #### maracas
* https://github.com/jfsantos/maracas
 ### <h3 id="5.2">Audio I/O</h3>
 #### PortAudio
* http://www.portaudio.com/
 #### audiolab
* https://github.com/cournape/audiolab
 #### Digital Speech Decoder
* https://github.com/szechyjs/dsd
 #### audioread
* https://github.com/beetbox/audioread
 #### audacity.py
* https://github.com/davidavdav/audacity.py
 ### <h3 id="5.3">Source Separation</h3>
 #### HARK
* https://www.hark.jp/wiki.cgi?page=HARK+Installation+Instructions
 ### <h3 id="5.4">Feature Extraction</h3>
 #### openSMILE
* https://audeering.com/technology/opensmile/


## <h2 id="6">资源</h2>
 ### cmusphinx
* https://github.com/cmusphinx
 #### julius-speech
* https://github.com/julius-speech
 #### OpenSLR
* http://www.openslr.org/
 #### List of speech recognition software
* https://en.wikipedia.org/wiki/List_of_speech_recognition_software
 #### VERBIO
* http://www.verbio.com/webverbiotm/html/productes.php?id=2
 #### Speech at CMU Web Page
* http://www.speech.cs.cmu.edu/
 #### CMU Robust Speech Group
* http://www.cs.cmu.edu/~robust/code.html
 #### Speech Software at CMU
* http://www.speech.cs.cmu.edu/hephaestus.html
 #### Aalto Speech Research
* https://github.com/aalto-speech
 #### CMU Festvox Project
* https://github.com/festvox?tab=repositories
* http://www.festvox.org/
 #### CSTR
* http://www.cstr.ed.ac.uk/research/
 #### Sparse Representation & Dictionary Learning Algorithms with Applications in Denoising, Separation, Localisation and Tracking
* http://personal.ee.surrey.ac.uk/Personal/W.Wang/codes.html
 #### Audacity
* https://www.audacityteam.org/
 #### beetbox
* https://github.com/beetbox

## <h3 id="7">主页</h3>
 #### cmusphinx
* https://github.com/cmusphinx
 #### CMU Language Technologies Institute
* https://www.lti.cs.cmu.edu/work
 #### MIT Spoken Language Systems
* https://groups.csail.mit.edu/sls/downloads/
